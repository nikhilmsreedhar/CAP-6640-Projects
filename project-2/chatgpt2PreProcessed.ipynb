{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade accelerate","metadata":{"ExecuteTime":{"end_time":"2024-03-08T03:15:48.811583Z","start_time":"2024-03-08T03:15:45.880304Z"},"execution":{"iopub.status.busy":"2024-03-12T09:34:11.124116Z","iopub.execute_input":"2024-03-12T09:34:11.124461Z","iopub.status.idle":"2024-03-12T09:34:25.494637Z","shell.execute_reply.started":"2024-03-12T09:34:11.124435Z","shell.execute_reply":"2024-03-12T09:34:25.493511Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# we upgraded `accelerate` just because to import Trainer API\nfrom transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForCausalLM\nfrom glob import glob\nfrom datasets import load_dataset\nimport warnings\nfrom datasets import Dataset\nwarnings.filterwarnings(\"ignore\")\nMODEL_NAME = \"gpt2\"","metadata":{"collapsed":false,"ExecuteTime":{"start_time":"2024-03-08T03:21:47.659368Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-12T09:34:25.496848Z","iopub.execute_input":"2024-03-12T09:34:25.497210Z","iopub.status.idle":"2024-03-12T09:34:43.963818Z","shell.execute_reply.started":"2024-03-12T09:34:25.497165Z","shell.execute_reply":"2024-03-12T09:34:43.962913Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-03-12 09:34:34.671372: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-12 09:34:34.671475: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-12 09:34:34.800086: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"\nclass DataPreprocessor:\n    def __init__(self, model_name=\"gpt2\", max_length=64):\n        # Initialize the DataPreprocessor with the specified model name and max_length\n        self.model_name = model_name\n        self.max_length = max_length\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.tokenizer.pad_token = \"<pad>\"\n    \n    def load_dataset(self, dataset_name, split=['train[:30%]', 'validation[:20%]']):\n        # Load the dataset using the specified split\n        try:\n            print(f\"Loading {dataset_name} dataset...\")\n            train_ds, validation_ds = load_dataset(dataset_name, split=split)\n            print(f\"Loaded {dataset_name} dataset.\")\n            return train_ds, validation_ds\n        except Exception as e:\n            print(f\"Error loading dataset: {e}\")\n            return None, None\n    \n    def preprocess(self, dataset):\n        # Preprocess the dataset by combining question and answer text\n        print(\"Preprocessing dataset...\")\n        def combine_text(example):\n            example[\"text\"] = (example[\"question\"] + \" \" + example[\"answers\"][\"text\"][0])\n            return example\n        \n        try:\n            preprocessed_dataset = dataset.map(combine_text, remove_columns=[\"id\", \"title\", \"context\", \"question\", \"answers\"])\n            print(\"Dataset preprocessing completed.\")\n            return preprocessed_dataset\n        except Exception as e:\n            print(f\"Error preprocessing dataset: {e}\")\n            return None\n    \n    def tokenize(self, dataset):\n        # Tokenize the dataset\n        print(\"Tokenizing dataset...\")\n        def tokenize_function(examples):\n            return self.tokenizer(examples[\"text\"], max_length=self.max_length, truncation=True, padding=\"max_length\")\n        \n        try:\n            tokenized_dataset = dataset.map(tokenize_function, batched=True, num_proc=2, remove_columns=[\"text\"])\n            print(\"Dataset tokenization completed.\")\n            return tokenized_dataset\n        except Exception as e:\n            print(f\"Error tokenizing dataset: {e}\")\n            return None\n    \n    def add_labels(self, dataset):\n        # Add labels to the dataset\n        print(\"Adding labels to dataset...\")\n        def copy_input_ids(example):\n            example[\"labels\"] = example[\"input_ids\"].copy()\n            return example\n        \n        try:\n            labeled_dataset = dataset.map(copy_input_ids)\n            print(\"Labels added to dataset.\")\n            return labeled_dataset\n        except Exception as e:\n            print(f\"Error adding labels to dataset: {e}\")\n            return None\n    \n    def preprocess_pipeline(self, dataset_name, split=['train[:30%]', 'validation[:20%]']):\n        # Execute the preprocessing pipeline\n        train_ds, validation_ds = self.load_dataset(dataset_name, split)\n        if train_ds is None or validation_ds is None:\n            # Dataset loading failed, return None\n            print(\"Preprocessing pipeline aborted due to dataset loading error.\")\n            return None, None\n        \n        train_ds = self.preprocess(train_ds)\n        validation_ds = self.preprocess(validation_ds)\n        if train_ds is None or validation_ds is None:\n            # Dataset preprocessing failed, return None\n            print(\"Preprocessing pipeline aborted due to dataset preprocessing error.\")\n            return None, None\n        \n        train_ds = self.tokenize(train_ds)\n        validation_ds = self.tokenize(validation_ds)\n        if train_ds is None or validation_ds is None:\n            # Dataset tokenization failed, return None\n            print(\"Preprocessing pipeline aborted due to dataset tokenization error.\")\n            return None, None\n        \n        train_ds = self.add_labels(train_ds)\n        validation_ds = self.add_labels(validation_ds)\n        if train_ds is None or validation_ds is None:\n            # Adding labels failed, return None\n            print(\"Preprocessing pipeline aborted due to label addition error.\")\n            return None, None\n        \n        return train_ds, validation_ds\n\n# Usage\npreprocessor = DataPreprocessor()\ntokenized_train_ds, tokenized_validation_ds = preprocessor.preprocess_pipeline('squad')","metadata":{"execution":{"iopub.status.busy":"2024-03-12T09:34:43.965646Z","iopub.execute_input":"2024-03-12T09:34:43.966671Z","iopub.status.idle":"2024-03-12T09:35:14.594696Z","shell.execute_reply.started":"2024-03-12T09:34:43.966634Z","shell.execute_reply":"2024-03-12T09:35:14.593857Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1b7024281b24ba2821ddbd9520f50f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48aaa5edee0f43739cb30485d2b80276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1077770661d4e66ba4ede49cea2f9db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2036e21ba05c49f29a873d47e1f5de6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c214b5fdbbd447b58b2f65b143694fa0"}},"metadata":{}},{"name":"stdout","text":"Loading squad dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad1efd4c3ac34e179c64b3376148a328"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9667832bf2946f0873d0bbf2bd140b7"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset squad/plain_text (download: 33.51 MiB, generated: 85.63 MiB, post-processed: Unknown size, total: 119.14 MiB) to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b255fd394a4b86a9d4148e9a64bb82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/8.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"865a8a1d2a964110958af0134f127f50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.05M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b3d6f1542e648b3903b205255d7535b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c13f4fc0bb3b4351a8c1f85d507d5b3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset squad downloaded and prepared to /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d713a7f7750d43879c75fb4e8c8844c3"}},"metadata":{}},{"name":"stdout","text":"Loaded squad dataset.\nPreprocessing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/26280 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87e7282eaf594aadb0905db70a095ea9"}},"metadata":{}},{"name":"stdout","text":"Dataset preprocessing completed.\nPreprocessing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2114 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c757f1ac0ffd470d94125e757e3f4c94"}},"metadata":{}},{"name":"stdout","text":"Dataset preprocessing completed.\nTokenizing dataset...\n   ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/14 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d851ef5740414068831fa609afdcb19c"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/14 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c504875c0e734d54b9bd028b8d815004"}},"metadata":{}},{"name":"stdout","text":"Dataset tokenization completed.\nTokenizing dataset...\n   ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faed06445981466c82f8c23625eae7ce"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"898ee8205ca64ec7baaa9144c23adb4b"}},"metadata":{}},{"name":"stdout","text":"Dataset tokenization completed.\nAdding labels to dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/26280 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"757e9d2cf53a478aa5770ce6ba40569d"}},"metadata":{}},{"name":"stdout","text":"Labels added to dataset.\nAdding labels to dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2114 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7687e3c6bd26476d9637a1d215ce15e7"}},"metadata":{}},{"name":"stdout","text":"Labels added to dataset.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-12T09:35:14.596737Z","iopub.execute_input":"2024-03-12T09:35:14.597076Z","iopub.status.idle":"2024-03-12T09:35:18.579129Z","shell.execute_reply.started":"2024-03-12T09:35:14.597049Z","shell.execute_reply":"2024-03-12T09:35:18.578029Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bd1ad2810e941fdb271d79944e8013a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23396a09751c4c25936b9a570480cbd1"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    \"gpt2-finetuned-on-squad\",\n    \n    num_train_epochs=5,\n    per_device_train_batch_size=64,\n    per_device_eval_batch_size=64,\n    dataloader_num_workers=2,\n\n    evaluation_strategy = \"steps\",\n    logging_strategy=\"steps\",\n    save_strategy=\"steps\",\n    eval_steps=0.1,\n    logging_steps=0.1,\n    save_steps=0.1,\n\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    save_total_limit=10,\n    report_to='none',\n)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-12T09:35:18.580651Z","iopub.execute_input":"2024-03-12T09:35:18.580989Z","iopub.status.idle":"2024-03-12T09:35:18.640911Z","shell.execute_reply.started":"2024-03-12T09:35:18.580943Z","shell.execute_reply":"2024-03-12T09:35:18.639764Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_ds,\n    eval_dataset=tokenized_validation_ds,\n)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-12T09:35:18.642425Z","iopub.execute_input":"2024-03-12T09:35:18.643311Z","iopub.status.idle":"2024-03-12T09:35:18.959991Z","shell.execute_reply.started":"2024-03-12T09:35:18.643270Z","shell.execute_reply":"2024-03-12T09:35:18.959200Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_output = trainer.train()\nprint(train_output)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-12T09:35:18.961179Z","iopub.execute_input":"2024-03-12T09:35:18.961534Z","iopub.status.idle":"2024-03-12T09:59:16.639488Z","shell.execute_reply.started":"2024-03-12T09:35:18.961500Z","shell.execute_reply":"2024-03-12T09:59:16.638515Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1030' max='1030' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1030/1030 23:53, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>103</td>\n      <td>1.230400</td>\n      <td>0.953940</td>\n    </tr>\n    <tr>\n      <td>206</td>\n      <td>0.996800</td>\n      <td>0.951242</td>\n    </tr>\n    <tr>\n      <td>309</td>\n      <td>0.938900</td>\n      <td>0.960785</td>\n    </tr>\n    <tr>\n      <td>412</td>\n      <td>0.929400</td>\n      <td>0.962202</td>\n    </tr>\n    <tr>\n      <td>515</td>\n      <td>0.893000</td>\n      <td>0.965030</td>\n    </tr>\n    <tr>\n      <td>618</td>\n      <td>0.895900</td>\n      <td>0.967117</td>\n    </tr>\n    <tr>\n      <td>721</td>\n      <td>0.872000</td>\n      <td>0.971241</td>\n    </tr>\n    <tr>\n      <td>824</td>\n      <td>0.867700</td>\n      <td>0.970373</td>\n    </tr>\n    <tr>\n      <td>927</td>\n      <td>0.855900</td>\n      <td>0.974493</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.854900</td>\n      <td>0.973988</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"TrainOutput(global_step=1030, training_loss=0.9334992936513956, metrics={'train_runtime': 1437.364, 'train_samples_per_second': 91.417, 'train_steps_per_second': 0.717, 'total_flos': 4291721625600000.0, 'train_loss': 0.9334992936513956, 'epoch': 5.0})\n","output_type":"stream"}]},{"cell_type":"code","source":"# TODO input prompt\nprompt = \"What is Beyonce's full name?\"\nencoded_prompt = preprocessor.tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\nencoded_prompt = encoded_prompt.to(trainer.model.device)\n# prediction\noutput_sequences = trainer.model.generate(\n    input_ids=encoded_prompt,\n    max_length=64,\n    min_length=1,\n    temperature=1.,\n    top_p=0.95,\n    do_sample=True,\n    num_return_sequences=10,\n    pad_token_id=preprocessor.tokenizer.pad_token_id,\n)\n\ngenerated_sequences = []\n\n# decode prediction\nfor generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n    generated_sequence = generated_sequence.tolist()\n    text = preprocessor.tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True, skip_special_tokens=False)\n    generated_sequences.append(text.strip())\n","metadata":{"execution":{"iopub.status.busy":"2024-03-12T10:08:28.283819Z","iopub.execute_input":"2024-03-12T10:08:28.284203Z","iopub.status.idle":"2024-03-12T10:08:30.063435Z","shell.execute_reply.started":"2024-03-12T10:08:28.284171Z","shell.execute_reply":"2024-03-12T10:08:30.062655Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"generated_sequences[3]","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-12T10:08:33.498437Z","iopub.execute_input":"2024-03-12T10:08:33.498775Z","iopub.status.idle":"2024-03-12T10:08:33.505285Z","shell.execute_reply.started":"2024-03-12T10:08:33.498750Z","shell.execute_reply":"2024-03-12T10:08:33.504021Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"\"What is Beyonce's full name? Taylor Swift<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\""},"metadata":{}}]},{"cell_type":"code","source":"directories = glob(\"/kaggle/working/gpt2-finetuned-on-squad/checkpoint-*\")\ndirectories.sort(key=lambda x: int(x.split(\"checkpoint-\")[1]))","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-12T10:08:33.905814Z","iopub.execute_input":"2024-03-12T10:08:33.906717Z","iopub.status.idle":"2024-03-12T10:08:33.912087Z","shell.execute_reply.started":"2024-03-12T10:08:33.906685Z","shell.execute_reply":"2024-03-12T10:08:33.910864Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"prompt_in_train = \"What is Beyonce's full name?\"  # in train data\nprompt_not_in_train = \"Who was Mongolia's first president?\"  # NOT in train data - but similar\nencoded_prompt_in_train = preprocessor.tokenizer(prompt_in_train, add_special_tokens=False, return_tensors=\"pt\").input_ids\nencoded_prompt_not_in_train = preprocessor.tokenizer(prompt_not_in_train, add_special_tokens=False, return_tensors=\"pt\").input_ids\n\nfor path in directories:\n    print(\"--------------\")\n    print(path)\n    print(\"--------------\")\n    _model = AutoModelForCausalLM.from_pretrained(path)\n\n    for _encoded_prompt in [encoded_prompt_in_train, encoded_prompt_not_in_train]:\n        output_sequences = _model.generate(\n            input_ids=_encoded_prompt,\n            max_length=64,\n            min_length=10,\n            temperature=1.,\n            top_p=0.95,\n            do_sample=True,\n            num_return_sequences=1,\n            pad_token_id=preprocessor.tokenizer.pad_token_id,\n        )\n\n        text = preprocessor.tokenizer.decode(output_sequences[0], clean_up_tokenization_spaces=True, skip_special_tokens=False)\n        \n        # Simplifying for demo\n        question, answer = text.split(\"?\")[:2]\n        answer = answer.split(\".\")[0]\n        print(question + \"?\", answer + \"...\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-12T10:08:59.182288Z","iopub.execute_input":"2024-03-12T10:08:59.183199Z","iopub.status.idle":"2024-03-12T10:09:10.403010Z","shell.execute_reply.started":"2024-03-12T10:08:59.183156Z","shell.execute_reply":"2024-03-12T10:09:10.401921Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"--------------\n/kaggle/working/gpt2-finetuned-on-squad/checkpoint-103\n--------------\nWhat is Beyonce's full name?  Sasha Banks<|endoftext|>...\nWho was Mongolia's first president?  Jiang Zemin<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-squad/checkpoint-206\n--------------\nWhat is Beyonce's full name?  Miss Universe<|endoftext|>...\nWho was Mongolia's first president?  the Dalai Lama<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-squad/checkpoint-309\n--------------\nWhat is Beyonce's full name?  Jane Austen<|endoftext|>...\nWho was Mongolia's first president?  Ming Kublai<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-squad/checkpoint-412\n--------------\nWhat is Beyonce's full name?   Rosemary<|endoftext|>...\nWho was Mongolia's first president?  Yücel<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-squad/checkpoint-515\n--------------\nWhat is Beyonce's full name?   Jennifer Lopez<|endoftext|>...\nWho was Mongolia's first president?  Tito the Hun<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-squad/checkpoint-618\n--------------\nWhat is Beyonce's full name?  Diana Gabaldon<|endoftext|>...\nWho was Mongolia's first president?  Aeneas II<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-squad/checkpoint-721\n--------------\nWhat is Beyonce's full name?  Alexis Michelle<|endoftext|>...\nWho was Mongolia's first president?  Ming dynasty ruler Yü Yong<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-squad/checkpoint-824\n--------------\nWhat is Beyonce's full name?  Beyoncé and Jay-Z<|endoftext|>...\nWho was Mongolia's first president?  Khabila Akto<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-squad/checkpoint-927\n--------------\nWhat is Beyonce's full name?  Beyoncé<|endoftext|>...\nWho was Mongolia's first president?  King George V<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-squad/checkpoint-1030\n--------------\nWhat is Beyonce's full name?  Beyonce Gives Back<|endoftext|>...\nWho was Mongolia's first president?  Khombe<|endoftext|>...\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}