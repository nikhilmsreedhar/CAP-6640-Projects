{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7879848,"sourceType":"datasetVersion","datasetId":4582055}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Building a chatbot on UCF FAQ data by fine-tuning GPT2 model\n### Installing accelerate and Parameter efficient fine-tuning library","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade accelerate\n!pip install peft","metadata":{"ExecuteTime":{"end_time":"2024-03-12T03:41:36.866819Z","start_time":"2024-03-12T03:41:33.970030Z"},"execution":{"iopub.status.busy":"2024-03-19T02:38:20.720941Z","iopub.execute_input":"2024-03-19T02:38:20.721608Z","iopub.status.idle":"2024-03-19T02:38:47.347992Z","shell.execute_reply.started":"2024-03-19T02:38:20.721575Z","shell.execute_reply":"2024-03-19T02:38:47.346929Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\nCollecting accelerate\n  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.27.2\n    Uninstalling accelerate-0.27.2:\n      Successfully uninstalled accelerate-0.27.2\nSuccessfully installed accelerate-0.28.0\nCollecting peft\n  Downloading peft-0.9.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.38.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.28.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.2)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.20.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.9.0-py3-none-any.whl (190 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.9.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Importing necessary packages","metadata":{}},{"cell_type":"code","source":"# we upgraded `accelerate` just because to import Trainer API\nfrom transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForCausalLM\nfrom peft import get_peft_config, get_peft_model, PeftModel, PeftConfig, LoraConfig, TaskType\nfrom glob import glob\nimport pandas as pd\nimport numpy as np\nimport os\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split","metadata":{"collapsed":false,"ExecuteTime":{"end_time":"2024-03-12T03:42:36.832898Z","start_time":"2024-03-12T03:42:35.812675Z"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-19T02:38:47.350152Z","iopub.execute_input":"2024-03-19T02:38:47.350493Z","iopub.status.idle":"2024-03-19T02:39:05.217945Z","shell.execute_reply.started":"2024-03-19T02:38:47.350461Z","shell.execute_reply":"2024-03-19T02:39:05.217021Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-03-19 02:38:56.386825: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-19 02:38:56.386946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-19 02:38:56.519982: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Initializing global constant variables","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = \"gpt2\"\nDATASET_NAME = \"/kaggle/input/faq-ucf/faqsUcfDataset.csv\"\nSPLIT = 0.2\nMAX_LENGTH = 256\nEPOCHS = 150","metadata":{"execution":{"iopub.status.busy":"2024-03-19T02:39:24.233491Z","iopub.execute_input":"2024-03-19T02:39:24.234245Z","iopub.status.idle":"2024-03-19T02:39:24.238866Z","shell.execute_reply.started":"2024-03-19T02:39:24.234205Z","shell.execute_reply":"2024-03-19T02:39:24.237806Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Defining a DataPreprocessor class that will:\n#### 1. Load dataset\n#### 2. Preprocess the dataset\n#### 3. Initialize an AutoTokenizer and use it to tokenize the dataset\n#### 4. Include labels to the dataset","metadata":{}},{"cell_type":"code","source":"class DataPreprocessor:\n    def __init__(self, model_name, max_length):\n        # Initialize the DataPreprocessor with the specified model name and max_length\n        self.model_name = model_name\n        self.max_length = max_length\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.tokenizer.pad_token = \"<pad>\"\n    \n    def load_dataset(self, dataset_name, split):\n        # Load the dataset using the specified split\n        try:\n            print(f\"Loading {dataset_name} dataset...\")\n            df = pd.read_csv(dataset_name)\n            train_ds, validation_ds = train_test_split(df, test_size=SPLIT)\n            train_ds = train_ds.reset_index()\n            validation_ds = validation_ds.reset_index()\n            print(f\"Loaded {dataset_name} dataset.\")\n            return train_ds, validation_ds\n        except Exception as e:\n            print(f\"Error loading dataset: {e}\")\n            return None, None\n    \n    def preprocess(self, dataset):\n        print(\"Preprocessing dataset...\")\n        try:\n            # Preprocess the dataset by combining question and answer text\n            dataset[\"text\"] = dataset[\"Q\"] + \" \" + dataset[\"A\"]\n            # Drop original columns\n            preprocessed_dataset = dataset.drop(['Q', 'A'], axis=1)\n            print(\"Dataset preprocessing completed.\")\n            return preprocessed_dataset\n        except Exception as e:\n            print(f\"Error preprocessing dataset: {e}\")\n            return None\n    \n    def tokenize(self, dataset):\n        # Tokenize the dataset\n        print(\"Tokenizing dataset...\")\n        def tokenize_function(examples):\n            return self.tokenizer(examples[\"text\"], max_length=self.max_length, truncation=True, padding=\"max_length\")\n        \n        try:\n            tokenized_dataset = dataset.apply(tokenize_function, axis=1)\n            print(\"Dataset tokenization completed.\")\n            return tokenized_dataset\n        except Exception as e:\n            print(f\"Error tokenizing dataset: {e}\")\n            return None\n    \n    def add_labels(self, dataset):\n        # Add labels to the dataset\n        print(\"Adding labels to dataset...\")\n        def copy_input_ids(example):\n            example[\"labels\"] = example[\"input_ids\"].copy()\n            return example\n        \n        try:\n            labeled_dataset = dataset.apply(copy_input_ids)\n            print(\"Labels added to dataset.\")\n            return labeled_dataset\n        except Exception as e:\n            print(f\"Error adding labels to dataset: {e}\")\n            return None\n    \n    def preprocess_pipeline(self, dataset_name, split):\n        # Execute the preprocessing pipeline\n        train_ds, validation_ds = self.load_dataset(dataset_name, split)\n        if train_ds is None or validation_ds is None:\n            # Dataset loading failed, return None\n            print(\"Preprocessing pipeline aborted due to dataset loading error.\")\n            return None, None\n        \n        train_ds = self.preprocess(train_ds)\n        validation_ds = self.preprocess(validation_ds)\n        if train_ds is None or validation_ds is None:\n            # Dataset preprocessing failed, return None\n            print(\"Preprocessing pipeline aborted due to dataset preprocessing error.\")\n            return None, None\n        \n        train_ds = self.tokenize(train_ds)\n        validation_ds = self.tokenize(validation_ds)\n        if train_ds is None or validation_ds is None:\n            # Dataset tokenization failed, return None\n            print(\"Preprocessing pipeline aborted due to dataset tokenization error.\")\n            return None, None\n        \n        train_ds = self.add_labels(train_ds)\n        validation_ds = self.add_labels(validation_ds)\n        if train_ds is None or validation_ds is None:\n            # Adding labels failed, return None\n            print(\"Preprocessing pipeline aborted due to label addition error.\")\n            return None, None\n        \n        return train_ds, validation_ds","metadata":{"execution":{"iopub.status.busy":"2024-03-19T02:39:05.226706Z","iopub.execute_input":"2024-03-19T02:39:05.227058Z","iopub.status.idle":"2024-03-19T02:39:05.258597Z","shell.execute_reply.started":"2024-03-19T02:39:05.227027Z","shell.execute_reply":"2024-03-19T02:39:05.257656Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Initializing a DataPreprocessor object and using it to load and preprocess UCF_FAQ dataset","metadata":{}},{"cell_type":"code","source":"# DataPreprocessor instance\npreprocessor = DataPreprocessor(MODEL_NAME, MAX_LENGTH)\n# Obtaining train, val datasets and tokenizing them\ntokenized_train_ds, tokenized_validation_ds = preprocessor.preprocess_pipeline(DATASET_NAME, SPLIT)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T02:39:05.259791Z","iopub.execute_input":"2024-03-19T02:39:05.260102Z","iopub.status.idle":"2024-03-19T02:39:07.310874Z","shell.execute_reply.started":"2024-03-19T02:39:05.260076Z","shell.execute_reply":"2024-03-19T02:39:07.309946Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0a877c324eb4155afcb0a8b578b088a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aae18c2cf8324f4a9b32f881c7021d95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"251b7a6935864f70a9d6f5fddfc4650c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72e7cf27531947149664b04120c65d79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a2b10bc5bba44dc8b6bc3da84a4d92c"}},"metadata":{}},{"name":"stdout","text":"Loading /kaggle/input/faq-ucf/faqsUcfDataset.csv dataset...\nLoaded /kaggle/input/faq-ucf/faqsUcfDataset.csv dataset.\nPreprocessing dataset...\nDataset preprocessing completed.\nPreprocessing dataset...\nDataset preprocessing completed.\nTokenizing dataset...\nDataset tokenization completed.\nTokenizing dataset...\nDataset tokenization completed.\nAdding labels to dataset...\nLabels added to dataset.\nAdding labels to dataset...\nLabels added to dataset.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Initializing pretrained GPT2 model","metadata":{}},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-19T02:39:07.312095Z","iopub.execute_input":"2024-03-19T02:39:07.312381Z","iopub.status.idle":"2024-03-19T02:39:10.430408Z","shell.execute_reply.started":"2024-03-19T02:39:07.312356Z","shell.execute_reply":"2024-03-19T02:39:10.429523Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8311ec7a1bd4cd5b2f2de5d8ccff3a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51369e0a6ec2434db414e7d9c77a1b19"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Initializing Low Rank Adaptation configurations\n### Advantages of using LoRA :\n- Trainable parameter reduction -> Less data is required for fine-tuning\n- Faster training\n- Uses less memory\n- PEFT library makes it look so easy!","metadata":{}},{"cell_type":"code","source":"peft_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,  # task_type, token classification (TaskType.CAUSAL_LM)\n    inference_mode=False,\n    r=8,                           # r, the dimension of the low-rank matrices\n    lora_alpha=16,                 # lora_alpha, scaling factor for the weight matrices\n    lora_dropout=0.3,              # lora_dropout, dropout probability of the LoRA layers\n    fan_in_fan_out=True,\n    bias=\"lora_only\"               # bias, set to only lora layers to train\n    \n)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T02:39:13.375763Z","iopub.execute_input":"2024-03-19T02:39:13.376175Z","iopub.status.idle":"2024-03-19T02:39:13.384630Z","shell.execute_reply.started":"2024-03-19T02:39:13.376143Z","shell.execute_reply":"2024-03-19T02:39:13.383685Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### Converting our pretrained GPT2 model to lora_model","metadata":{}},{"cell_type":"code","source":"# Converting our model to lora\nlora_model = get_peft_model(model, peft_config)\nlora_model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T02:39:13.677868Z","iopub.execute_input":"2024-03-19T02:39:13.678964Z","iopub.status.idle":"2024-03-19T02:39:14.481914Z","shell.execute_reply.started":"2024-03-19T02:39:13.678916Z","shell.execute_reply":"2024-03-19T02:39:14.480868Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.23643136409814364\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Initializing training arguments for fine-tuning job","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    \"gpt2-on-ucf-faq\",\n    # Number of epochs to train\n    num_train_epochs=EPOCHS,\n    # Training batch size\n    per_device_train_batch_size=32,\n    # Validation batch size\n    per_device_eval_batch_size=32,\n    # Number of parallel workers\n    dataloader_num_workers=2,\n\n    # Evaluating our model based on number of steps\n    evaluation_strategy = \"steps\",\n    logging_strategy=\"steps\",\n    save_strategy=\"steps\",\n    # Evaluate, log, and save the model every 150 steps\n    eval_steps=300,\n    logging_steps=300,\n    save_steps=300,\n\n    learning_rate=1e-3,\n    weight_decay=0.01,\n    save_total_limit=10,\n    report_to='none',\n\n    # Enabling the model to rollback to best checkpoint\n    load_best_model_at_end=True,\n)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-19T02:39:29.704048Z","iopub.execute_input":"2024-03-19T02:39:29.704719Z","iopub.status.idle":"2024-03-19T02:39:29.756271Z","shell.execute_reply.started":"2024-03-19T02:39:29.704684Z","shell.execute_reply":"2024-03-19T02:39:29.755401Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Building a trainer object on our model and training_arguments","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_ds,\n    eval_dataset=tokenized_validation_ds,\n)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-19T02:39:30.664788Z","iopub.execute_input":"2024-03-19T02:39:30.665731Z","iopub.status.idle":"2024-03-19T02:39:30.940843Z","shell.execute_reply.started":"2024-03-19T02:39:30.665697Z","shell.execute_reply":"2024-03-19T02:39:30.940019Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Training/Fine-tuning our lora-gpt2 model on UCF_FAQ dataset","metadata":{}},{"cell_type":"code","source":"os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\ntrain_output = trainer.train()\nprint(train_output)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-19T02:39:32.223087Z","iopub.execute_input":"2024-03-19T02:39:32.223988Z","iopub.status.idle":"2024-03-19T02:59:58.056375Z","shell.execute_reply.started":"2024-03-19T02:39:32.223941Z","shell.execute_reply":"2024-03-19T02:59:58.055380Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 20:23, Epoch 150/150]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>300</td>\n      <td>1.190700</td>\n      <td>0.944100</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.846800</td>\n      <td>0.917690</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.723000</td>\n      <td>0.925606</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.660100</td>\n      <td>0.932816</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.627200</td>\n      <td>0.932495</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n","output_type":"stream"},{"name":"stdout","text":"TrainOutput(global_step=1500, training_loss=0.8095712788899739, metrics={'train_runtime': 1225.5114, 'train_samples_per_second': 36.475, 'train_steps_per_second': 1.224, 'total_flos': 5860125337190400.0, 'train_loss': 0.8095712788899739, 'epoch': 150.0})\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"# Create a test prompt\nprompt = \"How long does it take for an electronic transcript to arrive at UCF?\"\n# Encode the prompt\nencoded_prompt = preprocessor.tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n# Transform the encoded representation to the device the model was trained on\nencoded_prompt = encoded_prompt.to(trainer.model.device)\n\n# Generating a prediction\noutput_sequences = trainer.model.generate(\n    input_ids=encoded_prompt,\n    # Maximum length of predicted sequence\n    max_length=MAX_LENGTH,\n    min_length=1,\n    # Temperature determines how creative/random or strict the model should be\n    temperature=.9,\n    # Determines the probability sum of tokens that should be kept\n    top_p=.95,\n    do_sample=True,\n    # Predict 3 sequences\n    num_return_sequences=3,\n    pad_token_id=preprocessor.tokenizer.pad_token_id,\n)\n\ngenerated_sequences = []\n\n# Decoding the predicted sequences\nfor generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n    generated_sequence = generated_sequence.tolist()\n    text = preprocessor.tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n    generated_sequences.append(text.strip().split('?')[1])\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-19T03:05:39.965361Z","iopub.execute_input":"2024-03-19T03:05:39.965732Z","iopub.status.idle":"2024-03-19T03:05:41.778378Z","shell.execute_reply.started":"2024-03-19T03:05:39.965704Z","shell.execute_reply":"2024-03-19T03:05:41.777373Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"generated_sequences","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-19T03:05:41.779970Z","iopub.execute_input":"2024-03-19T03:05:41.780283Z","iopub.status.idle":"2024-03-19T03:05:41.786360Z","shell.execute_reply.started":"2024-03-19T03:05:41.780256Z","shell.execute_reply":"2024-03-19T03:05:41.785369Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[' Electronic transcript processing takes approximately 5-10 business days for most UCF institutions. It takes approximately 5-10 business days to process an electronically submitted transcript.',\n ' Electronic transcripts typically arrive at the College of Graduate Studies within five to ten business days from the date of receipt of your application. If your transcript arrives at the College of Graduate Studies within five business days after receipt of your application, it may be delayed by up to 10 business days. If your transcript arrives at the College of Graduate Studies within seven business days after receipt of your application, it may be delayed by up to 10 business days.',\n ' Electronic transcripts usually arrive at the Office of Undergraduate Admissions at approximately five to ten business days after being sent from the institution of origin. If you receive an electronic transcript within five business days of being sent from the institution of origin, it may take up to five business days for your transcript to be processed. ETSech technicians are typically responsible for processing your transcript within seven business days after it is sent from the institution of origin to UCF. If you receive an electronic transcript within ten business days of being sent from the institution of origin to UCF, it may take up to ten business days for your transcript to be processed.']"},"metadata":{}}]},{"cell_type":"markdown","source":"## Running our chatbot","metadata":{}},{"cell_type":"code","source":"while True:\n    prompt = input(\"User > \")\n    if prompt:\n        if prompt == \"bye\":\n            break\n        encoded_prompt = preprocessor.tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n        encoded_prompt = encoded_prompt.to(trainer.model.device)\n\n        # prediction\n        output_sequences = trainer.model.generate(\n            input_ids=encoded_prompt,\n            max_length=MAX_LENGTH,\n            min_length=1,\n            temperature=.9,\n            top_p=.95,\n            do_sample=True,\n            num_return_sequences=1,\n            pad_token_id=preprocessor.tokenizer.pad_token_id,\n        )\n\n        generated_sequences = []\n\n        # decode prediction\n        for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n            generated_sequence = generated_sequence.tolist()\n            text = preprocessor.tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n            generated_sequences.append(text.strip().split(\"?\")[1])\n        print(\"Assistant > \", generated_sequences[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-19T03:07:32.114899Z","iopub.execute_input":"2024-03-19T03:07:32.115766Z","iopub.status.idle":"2024-03-19T03:08:29.845657Z","shell.execute_reply.started":"2024-03-19T03:07:32.115732Z","shell.execute_reply":"2024-03-19T03:08:29.844757Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdin","text":"User >  When should I apply to UCF?\n"},{"name":"stdout","text":"Assistant >   If you are applying to UCF, you should notify your Undergraduate Admissions Committee of any changes in your application, including an updated application, a revised transcript, and/or alternate transcript. Questions about transferring may be directed to the dean’s Undergraduate Admissions Committee at: http://ucf.edu/program/program-terms/.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User >  Does UCF have on-campus housing?\n"},{"name":"stdout","text":"Assistant >   Campsites and housing are on campus and located in four geographic areas: East, North, South, Central and Western. Campus housing can also be located in the Central, Central and Western areas, while the Campus Center is located in central, Central and Western.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User >  What is the admission rate of UCF?\n"},{"name":"stdout","text":"Assistant >   The U.S. Department of Higher Education (USD) requires a minimum admission fee of $12.75 for every class of admission, which includes all classes of students admitted to UCF during the same term (including graduation and transfer). If your class of admission meets the minimum admission criteria, you will receive a $8.75 fee. The minimum application fee is $50. After your application has been processed, a $20 fee is applied to your credit report. If you are applying for another term, the maximum application fee is $100. The minimum application fee is due at the close of term if approved. If you do not receive an acknowledgement from the administration within 15 business days of receipt of receipt of payment, you are not eligible for higher scholarships or fellowships. If you choose to receive a scholarship, the award must be sent or credited to your account within 15 business days after receipt of payment. Transfer students must submit an application electronically to UCF. All transfers and transfer students must submit an admission rate statement electronically, as described in the section titled Transfer and Transfer Programs. Your fee’s are determined by your school, the amount of your current student loan balance, your cumulative ACT and OCEA\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"User >  bye\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}