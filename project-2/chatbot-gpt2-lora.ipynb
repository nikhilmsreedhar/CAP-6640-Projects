{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 7820765,
     "sourceType": "datasetVersion",
     "datasetId": 4582055
    }
   ],
   "dockerImageVersionId": 30665,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade accelerate\n",
    "!pip install peft"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T03:41:36.866819Z",
     "start_time": "2024-03-12T03:41:33.970030Z"
    },
    "execution": {
     "iopub.status.busy": "2024-03-12T04:38:24.612481Z",
     "iopub.execute_input": "2024-03-12T04:38:24.613161Z",
     "iopub.status.idle": "2024-03-12T04:38:50.296963Z",
     "shell.execute_reply.started": "2024-03-12T04:38:24.613108Z",
     "shell.execute_reply": "2024-03-12T04:38:50.295784Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nCollecting peft\n  Downloading peft-0.9.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.38.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.27.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.2)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.20.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.9.0-py3-none-any.whl (190 kB)\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m190.9/190.9 kB\u001B[0m \u001B[31m6.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.9.0\n",
     "output_type": "stream"
    }
   ],
   "id": "94f8361021f22b34"
  },
  {
   "cell_type": "code",
   "source": [
    "# we upgraded `accelerate` just because to import Trainer API\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForCausalLM\n",
    "from glob import glob\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T03:42:36.832898Z",
     "start_time": "2024-03-12T03:42:35.812675Z"
    },
    "execution": {
     "iopub.status.busy": "2024-03-12T04:46:00.005972Z",
     "iopub.execute_input": "2024-03-12T04:46:00.006348Z",
     "iopub.status.idle": "2024-03-12T04:46:00.011564Z",
     "shell.execute_reply.started": "2024-03-12T04:46:00.006318Z",
     "shell.execute_reply": "2024-03-12T04:46:00.010573Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": [],
   "id": "5d5de52803374a49"
  },
  {
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('/kaggle/input/faq-ucf/faqsUcfDataset_2.csv')\n",
    "val = pd.read_csv('/kaggle/input/faq-ucf/faqsUcfDataset_val.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T03:42:27.421775Z",
     "start_time": "2024-03-12T03:42:27.405375Z"
    },
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:08.693995Z",
     "iopub.execute_input": "2024-03-12T04:39:08.694547Z",
     "iopub.status.idle": "2024-03-12T04:39:08.720028Z",
     "shell.execute_reply.started": "2024-03-12T04:39:08.694519Z",
     "shell.execute_reply": "2024-03-12T04:39:08.719114Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [],
   "id": "bcbb025f227ae916"
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess(df):\n",
    "    df[\"text\"] = df[\"Q\"] + \" \" + df[\"A\"]\n",
    "    df = df.drop(['Q', 'A'], axis=1)\n",
    "    return df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:08.721765Z",
     "iopub.execute_input": "2024-03-12T04:39:08.722059Z",
     "iopub.status.idle": "2024-03-12T04:39:08.732504Z",
     "shell.execute_reply.started": "2024-03-12T04:39:08.722036Z",
     "shell.execute_reply": "2024-03-12T04:39:08.731680Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [],
   "id": "4b07bb37bc1dfeaf"
  },
  {
   "cell_type": "code",
   "source": [
    "train = preprocess(train)\n",
    "val = preprocess(val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T03:42:28.442339Z",
     "start_time": "2024-03-12T03:42:28.431626Z"
    },
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:08.733612Z",
     "iopub.execute_input": "2024-03-12T04:39:08.733992Z",
     "iopub.status.idle": "2024-03-12T04:39:08.752222Z",
     "shell.execute_reply.started": "2024-03-12T04:39:08.733960Z",
     "shell.execute_reply": "2024-03-12T04:39:08.751292Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [],
   "id": "20032673aa04f276"
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO : choose model name\n",
    "MODEL_NAME = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = \"<pad>\""
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:15.869617Z",
     "iopub.execute_input": "2024-03-12T04:39:15.870293Z",
     "iopub.status.idle": "2024-03-12T04:39:17.950890Z",
     "shell.execute_reply.started": "2024-03-12T04:39:15.870262Z",
     "shell.execute_reply": "2024-03-12T04:39:17.949877Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2294fb2174c7466c8f58e98276004145"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89986a3350d244299679fafbc912ac2c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40ddd8b7b107431a9ffaa123be368da9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5715f2011fa44f2f89988aa9bbde1208"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddffcc5b46214028891091aa287819f4"
      }
     },
     "metadata": {}
    }
   ],
   "id": "f403277bc10d3825"
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], max_length=128, truncation=True, padding=\"max_length\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T03:43:07.798815Z",
     "start_time": "2024-03-12T03:43:07.789882Z"
    },
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:17.952635Z",
     "iopub.execute_input": "2024-03-12T04:39:17.952959Z",
     "iopub.status.idle": "2024-03-12T04:39:17.957809Z",
     "shell.execute_reply.started": "2024-03-12T04:39:17.952934Z",
     "shell.execute_reply": "2024-03-12T04:39:17.956886Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [],
   "id": "6aeb7cb2a3311195"
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train = train.apply(tokenize_function, axis=1)\n",
    "tokenized_val = val.apply(tokenize_function, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-12T03:43:10.257013Z",
     "start_time": "2024-03-12T03:43:09.001975Z"
    },
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:17.959242Z",
     "iopub.execute_input": "2024-03-12T04:39:17.959984Z",
     "iopub.status.idle": "2024-03-12T04:39:18.021425Z",
     "shell.execute_reply.started": "2024-03-12T04:39:17.959952Z",
     "shell.execute_reply": "2024-03-12T04:39:18.020582Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [],
   "id": "c48ba1a8eb4435bb"
  },
  {
   "cell_type": "code",
   "source": [
    "def copy_input_ids(example):\n",
    "    example[\"labels\"] = example[\"input_ids\"].copy()\n",
    "    return example"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:18.251332Z",
     "iopub.execute_input": "2024-03-12T04:39:18.252121Z",
     "iopub.status.idle": "2024-03-12T04:39:18.255922Z",
     "shell.execute_reply.started": "2024-03-12T04:39:18.252095Z",
     "shell.execute_reply": "2024-03-12T04:39:18.255066Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [],
   "id": "fcec0d756061b13b"
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train = tokenized_train.apply(copy_input_ids)\n",
    "tokenized_val = tokenized_val.apply(copy_input_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:18.933748Z",
     "iopub.execute_input": "2024-03-12T04:39:18.934463Z",
     "iopub.status.idle": "2024-03-12T04:39:18.939381Z",
     "shell.execute_reply.started": "2024-03-12T04:39:18.934432Z",
     "shell.execute_reply": "2024-03-12T04:39:18.938361Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [],
   "id": "89fbe20bf329e15b"
  },
  {
   "cell_type": "code",
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:19.980274Z",
     "iopub.execute_input": "2024-03-12T04:39:19.981151Z",
     "iopub.status.idle": "2024-03-12T04:39:22.853371Z",
     "shell.execute_reply.started": "2024-03-12T04:39:19.981117Z",
     "shell.execute_reply": "2024-03-12T04:39:22.852532Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abb41e192d1249808e27f25ad7439e3d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e284befb1a5444da40386ee68ea4460"
      }
     },
     "metadata": {}
    }
   ],
   "id": "ba9ab0b0125d125a"
  },
  {
   "cell_type": "code",
   "source": [
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,  # task_type, token classification (TaskType.CAUSAL_LM)\n",
    "    inference_mode=False,\n",
    "    r=8,                           # r, the dimension of the low-rank matrices\n",
    "    lora_alpha=16,                 # lora_alpha, scaling factor for the weight matrices\n",
    "    lora_dropout=0.3,              # lora_dropout, dropout probability of the LoRA layers\n",
    "    fan_in_fan_out=True,\n",
    "    bias=\"lora_only\"               # bias, set to only lora layers to train\n",
    "    \n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:22.855202Z",
     "iopub.execute_input": "2024-03-12T04:39:22.855496Z",
     "iopub.status.idle": "2024-03-12T04:39:22.861029Z",
     "shell.execute_reply.started": "2024-03-12T04:39:22.855470Z",
     "shell.execute_reply": "2024-03-12T04:39:22.860078Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [],
   "id": "574e0b3c92d9f50d"
  },
  {
   "cell_type": "code",
   "source": [
    "lora_model = get_peft_model(model, peft_config)\n",
    "lora_model.print_trainable_parameters()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:22.862133Z",
     "iopub.execute_input": "2024-03-12T04:39:22.862366Z",
     "iopub.status.idle": "2024-03-12T04:39:22.910874Z",
     "shell.execute_reply.started": "2024-03-12T04:39:22.862346Z",
     "shell.execute_reply": "2024-03-12T04:39:22.910091Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": "trainable params: 294,912 || all params: 124,734,720 || trainable%: 0.23643136409814364\n",
     "output_type": "stream"
    }
   ],
   "id": "1d0a08d2fdb2e946"
  },
  {
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"gpt2-on-ucf-faq\",\n",
    "    \n",
    "    num_train_epochs=300,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_num_workers=2,\n",
    "\n",
    "    evaluation_strategy = \"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=150,\n",
    "    logging_steps=150,\n",
    "    save_steps=150,\n",
    "\n",
    "    learning_rate=1e-3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=10,\n",
    "    report_to='none',\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:25.671383Z",
     "iopub.execute_input": "2024-03-12T04:39:25.671757Z",
     "iopub.status.idle": "2024-03-12T04:39:25.704382Z",
     "shell.execute_reply.started": "2024-03-12T04:39:25.671727Z",
     "shell.execute_reply": "2024-03-12T04:39:25.703428Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [],
   "id": "875b4dfe2111c461"
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:31.326668Z",
     "iopub.execute_input": "2024-03-12T04:39:31.327404Z",
     "iopub.status.idle": "2024-03-12T04:39:31.612368Z",
     "shell.execute_reply.started": "2024-03-12T04:39:31.327368Z",
     "shell.execute_reply": "2024-03-12T04:39:31.611327Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [],
   "id": "ed3e24852ad5c508"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:32.938204Z",
     "iopub.execute_input": "2024-03-12T04:39:32.938826Z",
     "iopub.status.idle": "2024-03-12T04:39:33.039767Z",
     "shell.execute_reply.started": "2024-03-12T04:39:32.938792Z",
     "shell.execute_reply": "2024-03-12T04:39:33.038882Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": [],
   "id": "beed28f4d63569ea"
  },
  {
   "cell_type": "code",
   "source": [
    "train_output = trainer.train()\n",
    "print(train_output)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-12T04:39:34.119854Z",
     "iopub.execute_input": "2024-03-12T04:39:34.120167Z",
     "iopub.status.idle": "2024-03-12T04:44:56.029808Z",
     "shell.execute_reply.started": "2024-03-12T04:39:34.120142Z",
     "shell.execute_reply": "2024-03-12T04:44:56.028826Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [900/900 05:20, Epoch 300/300]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>150</td>\n      <td>2.141100</td>\n      <td>1.593605</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.349000</td>\n      <td>1.148883</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.017500</td>\n      <td>0.958466</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.826100</td>\n      <td>0.855972</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.711600</td>\n      <td>0.807817</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.658000</td>\n      <td>0.793972</td>\n    </tr>\n  </tbody>\n</table><p>"
     },
     "metadata": {}
    },
    {
     "name": "stderr",
     "text": "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "TrainOutput(global_step=900, training_loss=1.1172228410508898, metrics={'train_runtime': 321.616, 'train_samples_per_second': 68.094, 'train_steps_per_second': 2.798, 'total_flos': 1435534059110400.0, 'train_loss': 1.1172228410508898, 'epoch': 300.0})\n",
     "output_type": "stream"
    }
   ],
   "id": "d3c1f5c7be111df5"
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO input prompt\n",
    "prompt = \"How long does it take for an electronic transcript to arrive at UCF?\"\n",
    "encoded_prompt = tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "encoded_prompt = encoded_prompt.to(trainer.model.device)\n",
    "\n",
    "# prediction\n",
    "output_sequences = trainer.model.generate(\n",
    "    input_ids=encoded_prompt,\n",
    "    max_length=128,\n",
    "    min_length=1,\n",
    "    temperature=1.,\n",
    "    top_p=1.,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=1,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "generated_sequences = []\n",
    "\n",
    "# decode prediction\n",
    "for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "    generated_sequence = generated_sequence.tolist()\n",
    "    text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True, skip_special_tokens=False)\n",
    "    generated_sequences.append(text.strip())\n"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-12T04:51:00.022729Z",
     "iopub.execute_input": "2024-03-12T04:51:00.023128Z",
     "iopub.status.idle": "2024-03-12T04:51:02.427201Z",
     "shell.execute_reply.started": "2024-03-12T04:51:00.023098Z",
     "shell.execute_reply": "2024-03-12T04:51:02.426370Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": [],
   "id": "5aa03ddc70ed4257"
  },
  {
   "cell_type": "code",
   "source": [
    "generated_sequences"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-03-12T04:51:04.426959Z",
     "iopub.execute_input": "2024-03-12T04:51:04.427714Z",
     "iopub.status.idle": "2024-03-12T04:51:04.433431Z",
     "shell.execute_reply.started": "2024-03-12T04:51:04.427683Z",
     "shell.execute_reply": "2024-03-12T04:51:04.432526Z"
    },
    "trusted": true
   },
   "execution_count": 32,
   "outputs": [
    {
     "execution_count": 32,
     "output_type": "execute_result",
     "data": {
      "text/plain": "['How long does it take for an electronic transcript to arrive at UCF? Electronic transcripts typically arrive at the university within six to eight business days after being sent from the institution of origin. Non-referrals to UCF for assistance happen at approximately five business days following receipt of the final document. Once served, documents begin arriving at the institution of origin within five to ten business days after being sent. Document processing time varies by time of year: Non-referrals to a Florida State University system typically 2-4 business hours prior to application completion stage (around application completion stage and the start of every semester).<|endoftext|>']"
     },
     "metadata": {}
    }
   ],
   "id": "91035be4a8257d6e"
  },
  {
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    prompt = input(\"User > \")\n",
    "    if prompt:\n",
    "        if prompt == \"bye\":\n",
    "            break\n",
    "        encoded_prompt = tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "        encoded_prompt = encoded_prompt.to(trainer.model.device)\n",
    "\n",
    "        # prediction\n",
    "        output_sequences = trainer.model.generate(\n",
    "            input_ids=encoded_prompt,\n",
    "            max_length=128,\n",
    "            min_length=1,\n",
    "            temperature=1.,\n",
    "            top_p=1.,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "\n",
    "        generated_sequences = []\n",
    "\n",
    "        # decode prediction\n",
    "        for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "            generated_sequence = generated_sequence.tolist()\n",
    "            text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True, skip_special_tokens=True)\n",
    "            generated_sequences.append(text.strip().split(\"?\")[1])\n",
    "        print(\"Assistant > \", generated_sequences[0])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-12T04:57:25.301225Z",
     "iopub.execute_input": "2024-03-12T04:57:25.301583Z",
     "iopub.status.idle": "2024-03-12T04:58:35.450241Z",
     "shell.execute_reply.started": "2024-03-12T04:57:25.301557Z",
     "shell.execute_reply": "2024-03-12T04:58:35.449402Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdin",
     "text": "User >  When should I apply to UCF?\n"
    },
    {
     "name": "stdout",
     "text": "Assistant >   UCF recommend freshman applicants with a West Coast college degree apply early (between May and September of your senior year). Freshmen should apply early in November (or whenever possible during the term of your senior year), as described in the guidelines below. In some instances, the admission date may be different than the date of the senior year. If you delay admission, you may still be referred to the Joseph T. Davis Institute for Higher Education for an official evaluation. This process is available on the UCF website and is described in the Instructions for Transfer Applicants under Advanced Admissions. In some cases,\n",
     "output_type": "stream"
    },
    {
     "output_type": "stream",
     "name": "stdin",
     "text": "User >  Does UCF have on-campus housing?\n"
    },
    {
     "name": "stdout",
     "text": "Assistant >   Yes, All-campus housing is available for admission to UCF under the UCF Living Room and Living Room Unit. Beginning in spring, the Living Room Unit will be closed for student housing only once in the semester following summer term. In the summer term, all students will be housed in the Living Room Unit. At a minimum, one living relative will need to be available to housing. For detailed information regarding this change, please visit www.ucf.edu/livingroom or use the livingroomunderground to locate roommates.\n",
     "output_type": "stream"
    },
    {
     "output_type": "stream",
     "name": "stdin",
     "text": "User >  What is the admission rate of UCF?\n"
    },
    {
     "name": "stdout",
     "text": "Assistant >   UCF accepts applications for full time, for full time employees and for those students who are assigned an academic post-secondary education benefit. Our program is a work-in-progress and requires extensive participation by all students, primarily from outside of high school, through to college or university education evaluation.\n",
     "output_type": "stream"
    },
    {
     "output_type": "stream",
     "name": "stdin",
     "text": "User >  bye\n"
    }
   ],
   "id": "538adaaf420c4c96"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "5e740e7b64fbf74c"
  }
 ]
}
