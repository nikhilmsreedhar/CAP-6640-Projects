{
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30665,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-08T03:15:48.811583Z",
          "start_time": "2024-03-08T03:15:45.880304Z"
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T18:55:33.748493Z",
          "iopub.execute_input": "2024-03-20T18:55:33.748881Z",
          "iopub.status.idle": "2024-03-20T18:55:47.989661Z",
          "shell.execute_reply.started": "2024-03-20T18:55:33.748853Z",
          "shell.execute_reply": "2024-03-20T18:55:47.988717Z"
        },
        "trusted": true,
        "id": "T965Lf7oSAxg",
        "outputId": "8180e9d6-ae6b-4b06-c689-3c2ed749e49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\nCollecting accelerate\n  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.27.2\n    Uninstalling accelerate-0.27.2:\n      Successfully uninstalled accelerate-0.27.2\nSuccessfully installed accelerate-0.28.0\n",
          "output_type": "stream"
        }
      ],
      "id": "T965Lf7oSAxg"
    },
    {
      "cell_type": "code",
      "source": [
        "# we upgraded `accelerate` just because to import Trainer API\n",
        "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForCausalLM\n",
        "from glob import glob\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2024-03-08T03:21:47.659368Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T18:55:47.991418Z",
          "iopub.execute_input": "2024-03-20T18:55:47.991722Z",
          "iopub.status.idle": "2024-03-20T18:56:05.525810Z",
          "shell.execute_reply.started": "2024-03-20T18:55:47.991696Z",
          "shell.execute_reply": "2024-03-20T18:56:05.525025Z"
        },
        "trusted": true,
        "id": "U8UUbaxhSAxi",
        "outputId": "99da83c9-95a9-460c-8cad-f6eb8b258b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-03-20 18:55:56.736288: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-20 18:55:56.736417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-20 18:55:56.859343: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "id": "U8UUbaxhSAxi"
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 64\n",
        "EPOCHS = 3\n",
        "MODEL = 'distilbert/distilgpt2'\n",
        "DATASET_NAME = 'wiki_movies'"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T18:56:05.526999Z",
          "iopub.execute_input": "2024-03-20T18:56:05.527600Z",
          "iopub.status.idle": "2024-03-20T18:56:05.531983Z",
          "shell.execute_reply.started": "2024-03-20T18:56:05.527572Z",
          "shell.execute_reply": "2024-03-20T18:56:05.531137Z"
        },
        "trusted": true,
        "id": "BrEageX7SAxj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "BrEageX7SAxj"
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreprocessor:\n",
        "    def __init__(self, model_name, max_length):\n",
        "        # Initialize the DataPreprocessor with the specified model name and max_length\n",
        "        self.model_name = model_name\n",
        "        self.max_length = max_length\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        self.tokenizer.pad_token = \"<pad>\"\n",
        "\n",
        "    def load_dataset(self, dataset_name):\n",
        "        # Load the dataset using the specified split\n",
        "        try:\n",
        "            print(f\"Loading {dataset_name} dataset...\")\n",
        "            train_ds, validation_ds = load_dataset(dataset_name, split=['train[:30%]', 'validation[:15%]'])\n",
        "            print(f\"Loaded {dataset_name} dataset.\")\n",
        "            return train_ds, validation_ds\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading dataset: {e}\")\n",
        "            return None, None\n",
        "\n",
        "    def preprocess(self, dataset):\n",
        "        print(\"Preprocessing dataset...\")\n",
        "        try:\n",
        "            def preprocess(example):\n",
        "                example[\"text\"] = (example[\"question\"] + \" \" + example[\"answer\"])\n",
        "                return example\n",
        "\n",
        "            preprocessed_dataset = dataset.map(preprocess, remove_columns=[\"question\", \"answer\"])\n",
        "            print(\"Dataset preprocessing completed.\")\n",
        "            return preprocessed_dataset\n",
        "        except Exception as e:\n",
        "            print(f\"Error preprocessing dataset: {e}\")\n",
        "            return None\n",
        "\n",
        "    def tokenize(self, dataset):\n",
        "        # Tokenize the dataset\n",
        "        print(\"Tokenizing dataset...\")\n",
        "        def tokenize_function(examples):\n",
        "            return self.tokenizer(examples[\"text\"], max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "\n",
        "        try:\n",
        "            tokenized_dataset = dataset.map(tokenize_function, batched=True, num_proc=2, remove_columns=[\"text\"])\n",
        "            print(\"Dataset tokenization completed.\")\n",
        "            return tokenized_dataset\n",
        "        except Exception as e:\n",
        "            print(f\"Error tokenizing dataset: {e}\")\n",
        "            return None\n",
        "\n",
        "    def add_labels(self, dataset):\n",
        "        # Add labels to the dataset\n",
        "        print(\"Adding labels to dataset...\")\n",
        "        def copy_input_ids(example):\n",
        "            example[\"labels\"] = example[\"input_ids\"].copy()\n",
        "            return example\n",
        "\n",
        "        try:\n",
        "            labeled_dataset = dataset.map(copy_input_ids)\n",
        "            print(\"Labels added to dataset.\")\n",
        "            return labeled_dataset\n",
        "        except Exception as e:\n",
        "            print(f\"Error adding labels to dataset: {e}\")\n",
        "            return None\n",
        "\n",
        "    def preprocess_pipeline(self, dataset_name):\n",
        "        # Execute the preprocessing pipeline\n",
        "        train_ds, validation_ds = self.load_dataset(dataset_name)\n",
        "        if train_ds is None or validation_ds is None:\n",
        "            # Dataset loading failed, return None\n",
        "            print(\"Preprocessing pipeline aborted due to dataset loading error.\")\n",
        "            return None, None\n",
        "\n",
        "        train_ds = self.preprocess(train_ds)\n",
        "        validation_ds = self.preprocess(validation_ds)\n",
        "        if train_ds is None or validation_ds is None:\n",
        "            # Dataset preprocessing failed, return None\n",
        "            print(\"Preprocessing pipeline aborted due to dataset preprocessing error.\")\n",
        "            return None, None\n",
        "\n",
        "        train_ds = self.tokenize(train_ds)\n",
        "        validation_ds = self.tokenize(validation_ds)\n",
        "        if train_ds is None or validation_ds is None:\n",
        "            # Dataset tokenization failed, return None\n",
        "            print(\"Preprocessing pipeline aborted due to dataset tokenization error.\")\n",
        "            return None, None\n",
        "\n",
        "        train_ds = self.add_labels(train_ds)\n",
        "        validation_ds = self.add_labels(validation_ds)\n",
        "        if train_ds is None or validation_ds is None:\n",
        "            # Adding labels failed, return None\n",
        "            print(\"Preprocessing pipeline aborted due to label addition error.\")\n",
        "            return None, None\n",
        "\n",
        "        return train_ds, validation_ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-20T18:56:05.534544Z",
          "iopub.execute_input": "2024-03-20T18:56:05.534920Z",
          "iopub.status.idle": "2024-03-20T18:56:05.563653Z",
          "shell.execute_reply.started": "2024-03-20T18:56:05.534884Z",
          "shell.execute_reply": "2024-03-20T18:56:05.562784Z"
        },
        "trusted": true,
        "id": "V9aH9iZZSAxj"
      },
      "execution_count": null,
      "outputs": [],
      "id": "V9aH9iZZSAxj"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_ds, tokenized_validation_ds = DataPreprocessor(MODEL, MAX_LENGTH).preprocess_pipeline(DATASET_NAME)"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T18:56:05.564689Z",
          "iopub.execute_input": "2024-03-20T18:56:05.564999Z",
          "iopub.status.idle": "2024-03-20T18:56:37.834525Z",
          "shell.execute_reply.started": "2024-03-20T18:56:05.564963Z",
          "shell.execute_reply": "2024-03-20T18:56:37.833450Z"
        },
        "trusted": true,
        "id": "GvKHzQekSAxk",
        "outputId": "a21ca0ee-4588-4768-8330-51b748617849",
        "colab": {
          "referenced_widgets": [
            "01ed2b7661c34b9cba9a87d0bdae8bfd",
            "28e74c39949d4242a49032bee3dae482",
            "32927ca891774cc1ba87993fb2fe5892",
            "6dfb70891dc34133a8f60cf68bec0cd4",
            "e764d413ae0348d1b38d0953d4e36ff3",
            "c608f1940a864b4f9ad70b30c234fcc7",
            "4cdc22fc4bf54a5eb608ba24db25d414",
            "f8db71c91378417384ffb7c1fa057cee",
            "",
            "92867f1d49ea4078a150dd8dd21b53cd",
            "f8d60f3324e9401d89e5b42ec7fb2ccf",
            "286aba03365a486fbab4eca67a528b9e",
            "7fa36409e03449d0b745b663378e976d",
            "de22d7825e2d44fa9563374bf612089f",
            "2ea0dfc678ba4a64b526b6f8bd8467b2",
            "d1aea65002404157b98962d66590fc65",
            "5fd4223a2e0d44be81fe73cc9edfc12b",
            "55e1015135244adaa89a47eab965900a"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01ed2b7661c34b9cba9a87d0bdae8bfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28e74c39949d4242a49032bee3dae482"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32927ca891774cc1ba87993fb2fe5892"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dfb70891dc34133a8f60cf68bec0cd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e764d413ae0348d1b38d0953d4e36ff3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Loading wiki_movies dataset...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/2.42k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c608f1940a864b4f9ad70b30c234fcc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading metadata:   0%|          | 0.00/825 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cdc22fc4bf54a5eb608ba24db25d414"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset wiki_movies/default (download: 54.43 MiB, generated: 8.38 MiB, post-processed: Unknown size, total: 62.80 MiB) to /root/.cache/huggingface/datasets/wiki_movies/default/1.1.0/2fab0fed49fad4c5854fcf8d4e958439d961e0d7de5d5ed2ca9ce54e309347cd...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/57.1M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8db71c91378417384ffb7c1fa057cee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/96185 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split:   0%|          | 0/9952 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset wiki_movies downloaded and prepared to /root/.cache/huggingface/datasets/wiki_movies/default/1.1.0/2fab0fed49fad4c5854fcf8d4e958439d961e0d7de5d5ed2ca9ce54e309347cd. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92867f1d49ea4078a150dd8dd21b53cd"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Loaded wiki_movies dataset.\nPreprocessing dataset...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/28856 [00:00<?, ?ex/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8d60f3324e9401d89e5b42ec7fb2ccf"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset preprocessing completed.\nPreprocessing dataset...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1500 [00:00<?, ?ex/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "286aba03365a486fbab4eca67a528b9e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset preprocessing completed.\nTokenizing dataset...\n   ",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "#0:   0%|          | 0/15 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fa36409e03449d0b745b663378e976d"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": " ",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "#1:   0%|          | 0/15 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de22d7825e2d44fa9563374bf612089f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset tokenization completed.\nTokenizing dataset...\n   ",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "#0:   0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ea0dfc678ba4a64b526b6f8bd8467b2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": " ",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "#1:   0%|          | 0/1 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1aea65002404157b98962d66590fc65"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset tokenization completed.\nAdding labels to dataset...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/28856 [00:00<?, ?ex/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fd4223a2e0d44be81fe73cc9edfc12b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Labels added to dataset.\nAdding labels to dataset...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1500 [00:00<?, ?ex/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55e1015135244adaa89a47eab965900a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Labels added to dataset.\n",
          "output_type": "stream"
        }
      ],
      "id": "GvKHzQekSAxk"
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(MODEL)"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T18:56:37.836101Z",
          "iopub.execute_input": "2024-03-20T18:56:37.836846Z",
          "iopub.status.idle": "2024-03-20T18:56:41.305665Z",
          "shell.execute_reply.started": "2024-03-20T18:56:37.836807Z",
          "shell.execute_reply": "2024-03-20T18:56:41.304738Z"
        },
        "trusted": true,
        "id": "mwsHMM1vSAxk",
        "outputId": "e699b7df-2061-4203-b5f4-2b840b13e79f",
        "colab": {
          "referenced_widgets": [
            "eac59ca5fdd14e2389bbd7882f17527e",
            "fa493e44ff364d079362a2fc067048fb"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eac59ca5fdd14e2389bbd7882f17527e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa493e44ff364d079362a2fc067048fb"
            }
          },
          "metadata": {}
        }
      ],
      "id": "mwsHMM1vSAxk"
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    \"gpt2-finetuned-on-wiki-movies\",\n",
        "\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    dataloader_num_workers=2,\n",
        "\n",
        "    evaluation_strategy = \"steps\",\n",
        "    logging_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    eval_steps=0.1,\n",
        "    logging_steps=0.1,\n",
        "    save_steps=0.1,\n",
        "\n",
        "    learning_rate=1e-5,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=10,\n",
        "    report_to='none',\n",
        ")"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T18:56:41.307163Z",
          "iopub.execute_input": "2024-03-20T18:56:41.307753Z",
          "iopub.status.idle": "2024-03-20T18:56:41.361243Z",
          "shell.execute_reply.started": "2024-03-20T18:56:41.307723Z",
          "shell.execute_reply": "2024-03-20T18:56:41.360238Z"
        },
        "trusted": true,
        "id": "M4IrsMRSSAxk"
      },
      "execution_count": null,
      "outputs": [],
      "id": "M4IrsMRSSAxk"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_ds,\n",
        "    eval_dataset=tokenized_validation_ds,\n",
        ")"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T18:56:41.362703Z",
          "iopub.execute_input": "2024-03-20T18:56:41.362992Z",
          "iopub.status.idle": "2024-03-20T18:56:41.593654Z",
          "shell.execute_reply.started": "2024-03-20T18:56:41.362966Z",
          "shell.execute_reply": "2024-03-20T18:56:41.592635Z"
        },
        "trusted": true,
        "id": "3oeW7RVoSAxl",
        "outputId": "735e37e0-6fe7-48e0-ac68-11b1ced366d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "id": "3oeW7RVoSAxl"
    },
    {
      "cell_type": "code",
      "source": [
        "train_output = trainer.train()\n",
        "print(train_output)"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T18:56:41.594859Z",
          "iopub.execute_input": "2024-03-20T18:56:41.595186Z",
          "iopub.status.idle": "2024-03-20T19:05:17.991210Z",
          "shell.execute_reply.started": "2024-03-20T18:56:41.595159Z",
          "shell.execute_reply": "2024-03-20T19:05:17.990282Z"
        },
        "trusted": true,
        "id": "FHXyv7mzSAxl",
        "outputId": "f99adad1-60e7-4e1d-eb2a-43cf8e015924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='1353' max='1353' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1353/1353 08:34, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>136</td>\n      <td>1.907500</td>\n      <td>1.458691</td>\n    </tr>\n    <tr>\n      <td>272</td>\n      <td>1.022800</td>\n      <td>1.433036</td>\n    </tr>\n    <tr>\n      <td>408</td>\n      <td>0.978000</td>\n      <td>1.432220</td>\n    </tr>\n    <tr>\n      <td>544</td>\n      <td>0.954400</td>\n      <td>1.433619</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.927200</td>\n      <td>1.438336</td>\n    </tr>\n    <tr>\n      <td>816</td>\n      <td>0.934900</td>\n      <td>1.438208</td>\n    </tr>\n    <tr>\n      <td>952</td>\n      <td>0.917900</td>\n      <td>1.439635</td>\n    </tr>\n    <tr>\n      <td>1088</td>\n      <td>0.914400</td>\n      <td>1.440559</td>\n    </tr>\n    <tr>\n      <td>1224</td>\n      <td>0.897000</td>\n      <td>1.442181</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "TrainOutput(global_step=1353, training_loss=1.0378565763598975, metrics={'train_runtime': 516.0368, 'train_samples_per_second': 167.755, 'train_steps_per_second': 2.622, 'total_flos': 1413746069078016.0, 'train_loss': 1.0378565763598975, 'epoch': 3.0})\n",
          "output_type": "stream"
        }
      ],
      "id": "FHXyv7mzSAxl"
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO input prompt\n",
        "prompt = \"When was cars 2 released?\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "encoded_prompt = tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "encoded_prompt = encoded_prompt.to(trainer.model.device)\n",
        "\n",
        "# prediction\n",
        "output_sequences = trainer.model.generate(\n",
        "    input_ids=encoded_prompt,\n",
        "    max_length=64,\n",
        "    min_length=1,\n",
        "    temperature=1.,\n",
        "    top_p=0.95,\n",
        "    do_sample=True,\n",
        "    num_return_sequences=10,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        ")\n",
        "\n",
        "generated_sequences = []\n",
        "\n",
        "# decode prediction\n",
        "for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
        "    generated_sequence = generated_sequence.tolist()\n",
        "    text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True, skip_special_tokens=False)\n",
        "    generated_sequences.append(text.strip())\n"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T19:05:17.994202Z",
          "iopub.execute_input": "2024-03-20T19:05:17.994592Z",
          "iopub.status.idle": "2024-03-20T19:05:20.097791Z",
          "shell.execute_reply.started": "2024-03-20T19:05:17.994564Z",
          "shell.execute_reply": "2024-03-20T19:05:20.096686Z"
        },
        "trusted": true,
        "id": "mDwWNHG_SAxm",
        "outputId": "44cb9529-de60-495e-8693-eff18ea24c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        }
      ],
      "id": "mDwWNHG_SAxm"
    },
    {
      "cell_type": "code",
      "source": [
        "generated_sequences[3]"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T19:05:20.098899Z",
          "iopub.execute_input": "2024-03-20T19:05:20.099235Z",
          "iopub.status.idle": "2024-03-20T19:05:20.105216Z",
          "shell.execute_reply.started": "2024-03-20T19:05:20.099206Z",
          "shell.execute_reply": "2024-03-20T19:05:20.104281Z"
        },
        "trusted": true,
        "id": "YdrUkfNPSAxm",
        "outputId": "74ca51bd-f66a-45d1-f8bd-135c50ac62a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'When was cars 2 released?\\n<|endoftext|><|endoftext|>'"
          },
          "metadata": {}
        }
      ],
      "id": "YdrUkfNPSAxm"
    },
    {
      "cell_type": "code",
      "source": [
        "directories = glob(\"/kaggle/working/gpt2-finetuned-on-wiki-movies/checkpoint-*\")\n",
        "directories.sort(key=lambda x: int(x.split(\"checkpoint-\")[1]))"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T19:05:20.106317Z",
          "iopub.execute_input": "2024-03-20T19:05:20.106609Z",
          "iopub.status.idle": "2024-03-20T19:05:20.114977Z",
          "shell.execute_reply.started": "2024-03-20T19:05:20.106585Z",
          "shell.execute_reply": "2024-03-20T19:05:20.114234Z"
        },
        "trusted": true,
        "id": "d6dzMqcsSAxm"
      },
      "execution_count": null,
      "outputs": [],
      "id": "d6dzMqcsSAxm"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_in_train = \"When was cars 2 released?\"  # in train data\n",
        "prompt_not_in_train = \"Which actors were in the movie cars 2?\"  # NOT in train data - but similar\n",
        "encoded_prompt_in_train = tokenizer(prompt_in_train, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "encoded_prompt_not_in_train = tokenizer(prompt_not_in_train, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
        "\n",
        "for path in directories:\n",
        "    print(\"--------------\")\n",
        "    print(path)\n",
        "    print(\"--------------\")\n",
        "    _model = AutoModelForCausalLM.from_pretrained(path)\n",
        "\n",
        "    for _encoded_prompt in [encoded_prompt_in_train, encoded_prompt_not_in_train]:\n",
        "        output_sequences = _model.generate(\n",
        "            input_ids=_encoded_prompt,\n",
        "            max_length=64,\n",
        "            min_length=10,\n",
        "            temperature=1.,\n",
        "            top_p=0.95,\n",
        "            do_sample=True,\n",
        "            num_return_sequences=1,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "        )\n",
        "\n",
        "        text = tokenizer.decode(output_sequences[0], clean_up_tokenization_spaces=True, skip_special_tokens=False)\n",
        "\n",
        "        # Simplifying for demo\n",
        "        question, answer = text.split(\"?\")[:2]\n",
        "        answer = answer.split(\".\")[0]\n",
        "        print(question + \"?\", answer + \"...\")"
      ],
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-03-20T19:05:20.117795Z",
          "iopub.execute_input": "2024-03-20T19:05:20.118152Z",
          "iopub.status.idle": "2024-03-20T19:05:26.038576Z",
          "shell.execute_reply.started": "2024-03-20T19:05:20.118127Z",
          "shell.execute_reply": "2024-03-20T19:05:26.037540Z"
        },
        "trusted": true,
        "id": "f0iajTtjSAxm",
        "outputId": "a3668f5d-c5ea-4afb-9c45-1c7cfa74f324"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--------------\n/kaggle/working/gpt2-finetuned-on-wiki-movies/checkpoint-136\n--------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "When was cars 2 released?  1997\n\nAdvertisements<|endoftext|>...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Which actors were in the movie cars 2?  Micky Proust, Tom Batson\n<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-wiki-movies/checkpoint-272\n--------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "When was cars 2 released?  1965\n\nAdvertisements<|endoftext|>...\nWhich actors were in the movie cars 2?  Richard Gannon\n<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-wiki-movies/checkpoint-408\n--------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "When was cars 2 released?  1965\nAdvertisements\n<|endoftext|>...\nWhich actors were in the movie cars 2?  Richard Farrar\n<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-wiki-movies/checkpoint-544\n--------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "When was cars 2 released?  2003\nAdvertisements\n<|endoftext|>...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Which actors were in the movie cars 2?  Davey, the Dolph Lundgren\n<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-wiki-movies/checkpoint-680\n--------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "When was cars 2 released?  1981\nAdvertisements\n<|endoftext|>...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Which actors were in the movie cars 2?  Bruce Springsteen, Bruce Springsteen, George Takei\n<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-wiki-movies/checkpoint-816\n--------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "When was cars 2 released?  1983\nAdvertisements\n<|endoftext|>...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Which actors were in the movie cars 2?  Chris Jones, Bob Dylan\n<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-wiki-movies/checkpoint-952\n--------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "When was cars 2 released?  1995\nAdvertisements\n<|endoftext|>...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Which actors were in the movie cars 2?  Frank Sinatra, I'm Here with you, Pops\n<|endoftext|>...\n--------------\n/kaggle/working/gpt2-finetuned-on-wiki-movies/checkpoint-1088\n--------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "When was cars 2 released?  2002\nAdvertisements\n<|endoftext|>...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Which actors were in the movie cars 2?  Joe, Bobby, John Belushi, John F...\n--------------\n/kaggle/working/gpt2-finetuned-on-wiki-movies/checkpoint-1224\n--------------\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "When was cars 2 released?  2001\nAdvertisements\n<|endoftext|>...\nWhich actors were in the movie cars 2?  Paul, Paulina\n<|endoftext|>...\n",
          "output_type": "stream"
        }
      ],
      "id": "f0iajTtjSAxm"
    }
  ]
}